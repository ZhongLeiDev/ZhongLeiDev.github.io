{"meta":{"title":"ZhongLeiDev","subtitle":"不忘初心，方得始终","description":"","author":"ZhongLeiDev","url":"http://yoursite.com","root":"/"},"pages":[{"title":"about","date":"2019-11-20T09:10:26.000Z","updated":"2019-11-20T09:10:26.709Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":""},{"title":"所有分类","date":"2019-11-20T06:14:16.000Z","updated":"2019-11-20T07:44:12.933Z","comments":true,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""},{"title":"读后感始化页面","date":"2019-11-19T01:03:22.000Z","updated":"2019-11-20T08:00:00.077Z","comments":true,"path":"bookreading/index.html","permalink":"http://yoursite.com/bookreading/index.html","excerpt":"","text":""},{"title":"相册初始化页面","date":"2019-11-20T05:49:45.000Z","updated":"2019-11-20T08:03:58.137Z","comments":true,"path":"albums/index.html","permalink":"http://yoursite.com/albums/index.html","excerpt":"","text":""},{"title":"所有标签","date":"2019-11-20T07:43:27.000Z","updated":"2019-11-20T07:45:00.917Z","comments":true,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""},{"title":"lab","date":"2019-11-20T09:17:50.000Z","updated":"2019-11-20T09:17:50.456Z","comments":true,"path":"lab/index.html","permalink":"http://yoursite.com/lab/index.html","excerpt":"","text":""},{"title":"感悟初始化页面","date":"2019-11-20T05:46:06.000Z","updated":"2019-11-20T08:02:42.602Z","comments":true,"path":"thinking/index.html","permalink":"http://yoursite.com/thinking/index.html","excerpt":"","text":""},{"title":"写作初始化页面","date":"2019-11-19T01:04:14.000Z","updated":"2019-11-20T08:50:19.226Z","comments":true,"path":"writing/index.html","permalink":"http://yoursite.com/writing/index.html","excerpt":"","text":""}],"posts":[{"title":"贪婪算法介绍","slug":"greedy","date":"2019-11-18T12:57:57.000Z","updated":"2019-11-20T08:46:36.065Z","comments":true,"path":"2019/11/18/greedy/","link":"","permalink":"http://yoursite.com/2019/11/18/greedy/","excerpt":"算法简介贪婪算法(贪心算法)是指在对问题进行求解时，在每一步选择中都采取最好或者最优(即最有利)的选择，从而希望能够导致结果是最好或者最优的算法。 贪婪算法所得到的结果往往不是最优的结果(有时候会是最优解)，但是都是相对近似(接近)最优解的结果。","text":"算法简介贪婪算法(贪心算法)是指在对问题进行求解时，在每一步选择中都采取最好或者最优(即最有利)的选择，从而希望能够导致结果是最好或者最优的算法。 贪婪算法所得到的结果往往不是最优的结果(有时候会是最优解)，但是都是相对近似(接近)最优解的结果。 贪婪算法并没有固定的算法解决框架，算法的关键是贪婪策略的选择，根据不同的问题选择不同的策略。 必须注意的是策略的选择必须具备无后效性，即某个状态的选择不会影响到之前的状态，只与当前状态有关，所以对采用的贪婪的策略一定要仔细分析其是否满足无后效性。 比如前边介绍的最短路径问题(广度优先、狄克斯特拉)都属于贪婪算法，只是在其问题策略的选择上，刚好可以得到最优解。 基本思路其基本的解题思路为： 1.建立数学模型来描述问题 2.把求解的问题分成若干个子问题 3.对每一子问题求解，得到子问题的局部最优解 4.把子问题对应的局部最优解合成原来整个问题的一个近似最优解 案例这边的案例来自”算法图解”一书 案例一区间调度问题: 假设有如下课程，希望尽可能多的将课程安排在一间教室里： 课程 开始时间 结束时间 美术 9AM 10AM 英语 9:30AM 10:30AM 数学 10AM 11AM 计算机 10:30AM 11:30AM 音乐 11AM 12PM 这个问题看似要思考很多，实际上算法很简单: 1.选择结束最早的课，便是要在这教室上课的第一节课 2.接下来，选择第一堂课结束后才开始的课，并且结束最早的课，这将是第二节在教室上的课。 重复这样做就能找出答案，这边的选择策略便是结束最早且和上一节课不冲突的课进行排序，因为每次都选择结束最早的，所以留给后面的时间也就越多，自然就能排下越多的课了。 每一节课的选择都是策略内的局部最优解(留给后面的时间最多)，所以最终的结果也是近似最优解(这个案例上就是最优解)。 (该案例的代码实现，就是一个简单的时间遍历比较过程) 案例二背包问题：有一个背包，容量为35磅 ， 现有如下物品 物品 重量 价格 吉他 15 1500 音响 30 3000 笔记本电脑 20 2000 显示器 29 2999 笔 1 200 要求达到的目标为装入的背包的总价值最大，并且重量不超出。 方便计算所以只有3个物品，实际情况可能是成千上万。 同上使用贪婪算法，因为要总价值最大，所以每次每次都装入最贵的,然后在装入下一个最贵的，选择结果如下： 选择: 音响 + 笔，总价值 3000 + 200 = 3200 并不是最优解: 吉他 + 笔记本电脑, 总价值 1500 + 2000 = 3500 当然选择策略有时候并不是很固定，可能是如下： (1)每次挑选价值最大的,并且最终重量不超出： 选择: 音响 + 笔，总价值 3000 + 200 = 3200 (2)每次挑选重量最大的,并且最终重量不超出(可能如果要求装入最大的重量才会优先考虑)： 选择: 音响 + 笔，总价值 3000 + 200 = 3200 (3)每次挑选单位价值最大的(价格/重量),并且最终重量不超出： 选择: 笔+ 显示器，总价值 200 + 2999 = 3199 如上最终的结果并不是最优解，在这个案例中贪婪算法并无法得出最优解，只能得到近似最优解,也算是该算法的局限性之一。该类问题中需要得到最优解的话可以采取动态规划算法(后续更新，也可以关注我的公众号第一时间获取更新信息)。 案例三集合覆盖问题: 假设存在如下表的需要付费的广播台，以及广播台信号可以覆盖的地区。 如何选择最少的广播台，让所有的地区都可以接收到信号。 广播台 覆盖地区 K1 ID,NV,UT K2 WA,ID,MT K3 OR,NV,CA K4 NV,UT K5 CA,AZ … … 如何找出覆盖所有地区的广播台的集合呢，听起来容易，实现起来很复杂，使用穷举法实现： (1) 列出每个可能的广播台的集合，这被称为幂集。假设总的有n个广播台，则广播台的组合总共有2ⁿ个【由组合及二项式定理得出：C(n,1)+C(n,2)+C(n,3)+…+C(n,n) = 2^n】 (2) 在这些集合中，选出覆盖全部地区的最小的集合，假设n不在，但是当n非常大的时候，假设每秒可以计算10个子集 广播台数量n 子集总数2ⁿ 需要的时间 5 32 3.2秒 10 1024 102.4秒 32 4294967296 13.6年 100 1.26*100³º 4x10²³年 目前并没有算法可以快速计算得到准备的值， 而使用贪婪算法，则可以得到非常接近的解，并且效率高: 选择策略上，因为需要覆盖全部地区的最小集合: (1) 选出一个广播台，即它覆盖了最多未覆盖的地区即便包含一些已覆盖的地区也没关系 (2) 重复第一步直到覆盖了全部的地区 这是一种近似算法（approximation algorithm，贪婪算法的一种）。在获取到精确的最优解需要的时间太长时，便可以使用近似算法，判断近似算法的优劣标准如下: 速度有多快 得到的近似解与最优解的接近程度 在本例中贪婪算法是个不错的选择，不仅运行速度快，本例运行时间O(n²),最坏的情况，假设n个广播台，每个广播台就覆盖1个地区,n个地区，总计需要查询n*n=O(n²),实现可查看后面的java代码实现 广播台数量n 子集总数2ⁿ 穷举需要时间 贪婪算法 5 32 3.2秒 2.5秒 10 32 102.4秒 10秒 32 32 13.6年 102.4秒 100 32 4x10²³年 1000秒 此时算法选出的是K1, K2, K3, K5，符合覆盖了全部的地区，可能不是预期中的K2, K3,K4,K5(也许预期中的更便宜，更便于实施等等) NP完全问题案例四旅行商问题 假设有旅行商需要从下面三个城市的某一个城市出发，如何规划路线获取行程的最短路径。 存在3！(阶乘)=6种可能情况: A-&gt;B-&gt;C A-&gt;C-&gt;B B-&gt;A-&gt;C B-&gt;C-&gt;A C-&gt;A-&gt;B C-&gt;B-&gt;A 这边和之前求最短路径的算法(广度搜索、狄克斯特拉、贝尔曼-福特)，最大的差别是没有固定源点(起点),，每一个节点都可能是源点，并且需要经过每一个节点，所以若穷举法则不得不找出每一种可能并进行比较。 当城市数量为n,则可能性为n!，假设每秒处理判断一个路线 数量n 总数n! 穷举需要时间 5 120 120秒 10 32 42天 而使用贪婪算法，随机选择从一个城市出发，比如A，每次选择从最近的还没去过的城市出发,则可以得到近似最优解。 第一次比较n-1个城市 第二次比较n-2个城市 … 第n-1次比较1个城市 第n次不存在需要比较的了个 0+1+2+3+..+(n-1) ≈ O(n²/2) 数量n 总数n! 穷举需要时间 贪婪需要时间 5 120 120秒 12.5秒 10 32 42天 50秒 类似上述集合覆盖问题、旅行商问题，都属于NP完全问题，在数学领域上并没有快速得到最优解的方案，贪婪算法是最适合处理这类问题的了。 如何判断是NP完全问题的:1.元素较少时，一般运行速度很快，但随着元素数量增多，速度会变得非常慢 2.涉及到需要计算比较”所有的组合”情况的通常是NP完全问题 3.无法分割成小问题，必须考虑各种可能的情况。这可能是NP完全问题 4.如果问题涉及序列（如旅行商问题中的城市序列）且难以解决，它可能就是NP完全问题 5.如果问题涉及集合（如广播台集合）且难以解决，它可能就是NP完全问题 6.如果问题可转换为集合覆盖问题或旅行商问题，那它肯定是NP完全问题 小结1.贪婪算法可以寻找局部最优解，并尝试与这种方式获得全局最优解 2.得到的可能是近似最优解，但也可能便是最优解(区间调度问题，最短路径问题(广度优先、狄克斯特拉)) 3.对于完全NP问题，目前并没有快速得到最优解的解决方案 4.面临NP完全问题，最佳的做法就是使用近似算法 5.贪婪算法(近似算法)在大部分情况下易于实现，并且效率不错 JAVA 实现贪婪算法需要根据具体问题，选择对应的策略来实现，所以这边只取集合覆盖问题做个示例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/** * 贪婪算法 - 集合覆盖问题 * @author Administrator * */ public class Greedy &#123; public static void main(String[] args)&#123; //初始化广播台信息 HashMap&lt;String,HashSet&lt;String&gt;&gt; broadcasts = new HashMap&lt;String,HashSet&lt;String&gt;&gt;(); broadcasts.put(\"K1\", new HashSet(Arrays.asList(new String[]&#123;\"ID\",\"NV\",\"UT\"&#125;))); broadcasts.put(\"K2\", new HashSet(Arrays.asList(new String[] &#123;\"WA\",\"ID\",\"MT\"&#125;))); broadcasts.put(\"K3\", new HashSet(Arrays.asList(new String[] &#123;\"OR\",\"NV\",\"CA\"&#125;))); broadcasts.put(\"K4\", new HashSet(Arrays.asList(new String[] &#123;\"NV\",\"UT\"&#125;))); broadcasts.put(\"K5\", new HashSet(Arrays.asList(new String[] &#123;\"CA\",\"AZ\"&#125;))); //需要覆盖的全部地区 HashSet&lt;String&gt; allAreas = new HashSet(Arrays.asList(new String[] &#123;\"ID\",\"NV\",\"UT\",\"WA\",\"MT\",\"OR\",\"CA\",\"AZ\"&#125;)); //所选择的广播台列表 List&lt;String&gt; selects = new ArrayList&lt;String&gt;(); HashSet&lt;String&gt; tempSet = new HashSet&lt;String&gt;(); String maxKey = null; while(allAreas.size()!=0) &#123; maxKey = null; for(String key : broadcasts.keySet()) &#123; tempSet.clear(); HashSet&lt;String&gt; areas = broadcasts.get(key); tempSet.addAll(areas); //求出2个集合的交集，此时tempSet会被赋值为交集的内容，所以使用临时变量 tempSet.retainAll(allAreas); //如果该集合包含的地区数量比原本的集合多 if (tempSet.size()&gt;0 &amp;&amp; (maxKey == null || tempSet.size() &gt; broadcasts.get(maxKey).size())) &#123; maxKey = key; &#125; &#125; if (maxKey != null) &#123; selects.add(maxKey); allAreas.removeAll(broadcasts.get(maxKey)); &#125; &#125; System.out.print(\"selects:\" + selects); &#125; &#125; 执行完main方法打印信息如下: 1selects:[K1, K2, K3, K5] 参考：https://www.cnblogs.com/steven_oyj/archive/2010/05/22/1741375.html 原文链接：https://www.jianshu.com/p/fede80bad3f1","categories":[],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"http://yoursite.com/tags/algorithm/"}]},{"title":"SHA(安全散列算法)简单实现","slug":"sha","date":"2019-11-18T12:42:00.000Z","updated":"2019-11-18T13:20:09.270Z","comments":true,"path":"2019/11/18/sha/","link":"","permalink":"http://yoursite.com/2019/11/18/sha/","excerpt":"摘要算法：SHA 及 Java 实现样例 SHA = 安全散列算法（Secure Hash Algorithm）。 SHA 与 MD5 类似，都是单向不可逆散列函数，用于计算消息摘要，生成消息数字签名（指纹）。","text":"摘要算法：SHA 及 Java 实现样例 SHA = 安全散列算法（Secure Hash Algorithm）。 SHA 与 MD5 类似，都是单向不可逆散列函数，用于计算消息摘要，生成消息数字签名（指纹）。 Algorithm 散列值长度（单位比特） SHA-1 160 SHA-224 224 SHA-256 256 SHA-384 384 SHA-512 512 Java 实现样例： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647import java.security.MessageDigest; public class MySHA &#123; public static void main(String[] args) throws Exception &#123; // TODO Auto-generated method stub String msg = \"0123456789abcdef\"; MessageDigest sha = MessageDigest.getInstance(\"SHA\"); sha.update(msg.getBytes()); byte []shaBin = sha.digest(); printBytes(shaBin); MessageDigest sha1 = MessageDigest.getInstance(\"SHA-1\"); sha1.update(msg.getBytes()); printBytes(sha1Bin); MessageDigest sha224 = MessageDigest.getInstance(\"SHA-224\"); sha224.update(msg.getBytes()); byte []sha224Bin = sha224.digest(); printBytes(sha224Bin); MessageDigest sha256 = MessageDigest.getInstance(\"SHA-256\"); sha256.update(msg.getBytes()); byte []sha256Bin = sha256.digest(); printBytes(sha256Bin); MessageDigest sha384 = MessageDigest.getInstance(\"SHA-384\"); sha384.update(msg.getBytes()); byte []sha384Bin = sha384.digest(); printBytes(sha384Bin); MessageDigest sha512 = MessageDigest.getInstance(\"SHA-512\"); sha512.update(msg.getBytes()); byte []sha512Bin = sha512.digest(); printBytes(sha512Bin); &#125; &#125; /** * 十六进制打印字节数组 * @param b byte[] */ public static void printBytes(byte[] b) &#123; for(int i=0;i&lt;b.length;i++) &#123; System.out.printf(\"%02X\", b[i]); &#125; System.out.println(); &#125; &#125; 注：散列值都是按照十六进制大写字母编码表示 很多人肯定会出来反驳，加密简单的123456可以在某些解密网站直接解密出来。 在这样的情况下，我们可以尝试在字符串追加其他文字如yangzhangyin，实际如下： 123456789101112131415161718192021222324import java.math.BigInteger; import java.security.MessageDigest; public class SHAEncryption &#123; public static byte[] encryptSHA(byte[] data, String shaN) throws Exception &#123; MessageDigest sha = MessageDigest.getInstance(shaN); sha.update(data); return sha.digest(); &#125; public static String encryptFlychordPwd(String str) &#123; byte[] outputData = new byte[0]; try &#123; outputData = encryptSHA((str+\"yangzhangyin\").getBytes(), \"SHA-256\"); return new BigInteger(1, outputData).toString(16); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return \"\"; &#125; public static void main(String[] args) &#123; //加密123456 System.out.println(ss.encryptFlychordPwd(\"123456\")); &#125; &#125; 这样就解决了简单密码被解密的问题啦。","categories":[],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"http://yoursite.com/tags/algorithm/"},{"name":"java","slug":"java","permalink":"http://yoursite.com/tags/java/"}]},{"title":"Diffie-Hellman（秘钥协商算法）介绍","slug":"diffie-hellman","date":"2019-11-18T12:35:06.000Z","updated":"2019-11-19T00:48:49.698Z","comments":true,"path":"2019/11/18/diffie-hellman/","link":"","permalink":"http://yoursite.com/2019/11/18/diffie-hellman/","excerpt":"一、概述 Diffie-Hellman密钥协商算法主要解决秘钥配送问题，本身并非用来加密用的；该算法其背后有对应数学理论做支撑，简单来讲就是构造一个复杂的计算难题，使得对该问题的求解在现实的时间内无法快速有效的求解（computationally infeasible ）。","text":"一、概述 Diffie-Hellman密钥协商算法主要解决秘钥配送问题，本身并非用来加密用的；该算法其背后有对应数学理论做支撑，简单来讲就是构造一个复杂的计算难题，使得对该问题的求解在现实的时间内无法快速有效的求解（computationally infeasible ）。 理解Diffie-Hellman密钥协商的原理并不困难，只需要一点数论方面的知识既可以理解，主要会用到简单的模算术运算、本原根、费马小定理、离散对数等基础数论的知识。在现代密码学中的基础数论知识梳理中已经对这些知识做了必要的总结。 二、从何而来 DH密钥协商算法在1976年在Whitfield Diffie和Martin Hellman两人合著的论文New Directions in Cryptography（Section Ⅲ PUBLIC KEY CRYPTOGRAPHY）中被作为一种公开秘钥分发系统(public key distribution system)被提出来。原文的叙述过程比较简单，但基本阐述了算法的原理以及其可行性。 在该论文中实际上提出了一些在当时很有创新性的思想。原论文重点讨论两个话题： （1）在公网通道上如何进行安全的秘钥分派。 （2）认证（可以细分为消息认证和用户认证）。 为了解决第一个问题，原文提出两种方法：公钥加密系统(public key cryptosystem)和秘钥分发系统(public key distribution system)。对于公钥加密系统，原文只是勾画了一种比较抽象的公钥加密系统的概念模型，重点是加解密采用不同的秘钥，并总结了该系统应该满足的一些特性，相当于是一种思想实验，并没有给出具体的算法实现途径，但这在当时应该来说已经足够吸引人。后来RSA三人组（Ron Rivest、Adi Shamir 和 Leonard Adleman）受此启发，经过许多轮失败的尝试后，于第二年在论文A Method for Obtaining Digital Signatures and Public-Key Cryptosystems中提出了切实可行且很具体的公钥加密算法–RSA公钥加密算法。而对于秘钥分发系统，就是本文的DH秘钥协商算法。 为了解决第二个问题，原文通过单向函数（one-way function）来解决，这就是单向认证的问题。另外作者还讨论了这些密码学问题之间的关联性以及如何相互转化。比如一个安全的密码系统（可以防御明文攻击）可以用来生成一个的单向函数、公钥加密系统可以用来作为单向认证、陷门密码系统可以用来生成一个公钥加密系统。数学难题的计算复杂度被当成一种保障密码学安全问题的有效工具被利用起来，这一重要思想贯穿现代密码学的许多加密算法。 三、算法流程及原理 按照惯例，以Alice和Bob这两个密码学中的网红为角色，述阐DH算法的流程。 假设Alice需要与Bob协商一个秘钥（秘钥本质上就是一个比特序列，从计算的角度看就是一个大数）。 1）首先Alice与Bob共享一个素数p以及该素数p的本原根g（geneator），当然这里有2⩽g⩽p−1。这两个数是可以不经过加密地由一方发送到另一方，至于谁发送给并不重要，其结果只要保证双方都得知p和g即可。 2）然后Alice产生一个私有的随机数A，满足1⩽A⩽p−1，然后计算gAmodp=Ya，将结果Ya通过公网发送给Bob；与此同时，Bob也产生一个私有的随机数B，满足1⩽B⩽p−1，计算gBmodp=Yb，将结果Yb通过公网发送给Alice。 3）此时Alice知道的信息有p,g,A,Ya，其中数字A是Alice私有的，只有她自己知道，别人不可能知道，其他三个信息都是别人有可能知道的；Bob知道的信息有p,g,B,Yb，其中数字B是Bob私有的，只有他自己知道，别人不可能知道，其他都是别人有可能知道的。 到目前为止，Alice和Bob之间的秘钥协商结束。 Alice通过计算Ka=(Yb)Amodp得到秘钥Ka，同理，Bob通过计算Kb=(Ya)Bmodp得到秘钥Kb，此时可以证明，必然满足Ka=Kb。因此双方经过协商后得到了相同的秘钥，达成秘钥协商的目的。 证明： 对于Alice有： Ka=(Yb)Amodp=(gBmodp)Amodp=gB×Amodp 对于Bob有： Kb=(Ya)Bmodp=(gAmodp)Bmodp=gA×Bmodp 可见，Alice和Bob生成秘钥时其实是进行相同的运算过程，因此必然有Ka=Kb。”相同的运算过程”是双方能够进行秘钥协商的本质原因，类似的利用椭圆曲线进行秘钥协商也是与之相同的原理。 更严密地考虑，A和B不应该选择p−1，也就是说只能在集合{1,2,3,…,p−2}中选择。这是因为如果选择p−1，那么由费马小定理可知，情况就退化成了gp−1≡1(modp)的情况，对秘钥协商的机密性构成威胁。 所以总结起来，整个流程串起来大概就是这样： 那么窃听者Eve能否破解秘钥呢？首先要知道Eve能够得知哪些信息，显然Eve能够窃听到的信息只能有p,g,Ya,Yb，现在的问题是Eve能够通过以上信息计算出Ka或者Kb吗？要计算Ka或者Kb需要知道A或者B。 以计算A为例，Eve能根据条件gAmodp=Ya计算出A吗？实际上当p是大质数的时候，这是相当困难的，这就是离散对数问题。实际上在论文发表的当时，计算该问题的最有效的算法的时间复杂度大约是O(p–√)。也正是求解该问题在计算上的困难程度保证了DH算法的安全性。如果能够找到对数时间复杂度的算法，那么该算法即容易被攻破。 四、一个实例 1）假设Alice和Bob共享的p和g分别是p=17,g=3，显然这里g=3是p=17的一个本原根，实际上3,5,6,7,10,11,12,14都是17的本原根。 2）然后Alice选定一个私有数字，假设A=15，计算Ya=315mod17=14348907mod17=6，将6发送给Bob；同时Bob也选定一个私有的数字，假设B=13，计算Ya=313mod17=1594323mod17=12，将12发送给Alice。 3）Alice计算秘钥Ka=1215mod17=2147483647mod17=8，Bob计算秘钥Kb=613mod17=2147483647mod17=8。双方经过协商后，8最终成为双方的协商的秘钥。 实际上，当指数和模数的位数都比较大的时候，存在一种快速计算幂取模的算法叫做“反复平方算法”，实现取来也比较简单，在算法导论中第三十一章有相应的解释。 五、存在的问题 是否DH秘钥协商算法就一定安全呢？应该说也不是，因为存在一种伪装者攻击（或者称为中间人攻击）能够对这种秘钥协商算法构成威胁。 假设秘钥协商过程中，在Alice和Bob中间有一个称为Mallory的主动攻击者，他能够截获Alice和Bob的消息并伪造假消息，考虑如下情况。 1）Alice和Bob已经共享一个素数p及其该素数p的本原根g，当然Mallory监听到报文也得知了这两个消息。 2）此时Alice计算Ya=gAmodp，然而在将Ya发送给Bob的过程中被Mallory拦截，Mallory自己选定一个随机数S，计算Ysb=gSmodp，然后将Ysb发送给了Bob。 3）同时Bob计算Yb=gBmodp，然而在将Yb发送给Alice的过程中被Mallory拦截，Mallory自己选定一个随机数T，计算Yta=gTmodp，然后将Yta发送给了Alice。 由于通讯消息被替换，Alice计算出的秘钥实际上是Alice和Mallory之间协商秘钥：Kam=gA×Tmodp；Bob计算出的秘钥实际上是Bob与Mallory之间协商的秘钥：Kbm=gB×Smodp。如果之后Alice和Bob用他们计算出的秘钥加密任何信息，Mallory截获之后都能够解密得到明文，而且Mallory完全可以伪装成Alice或者Bob给对方发消息。 六、References 1、New Directions in Cryptography 2、密码编码学与网络安全原理与实践 3、图解密码技术 原文出处：http://www.cnblogs.com/qcblog/p/9016704.html","categories":[],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"http://yoursite.com/tags/algorithm/"}]},{"title":"Simhash算法介绍","slug":"simhash","date":"2019-11-18T12:20:56.000Z","updated":"2019-11-19T00:54:23.971Z","comments":true,"path":"2019/11/18/simhash/","link":"","permalink":"http://yoursite.com/2019/11/18/simhash/","excerpt":"Simhash的生成及存储 一、背景介绍 根据 Detecting Near-Duplicates for Web Crawling 论文中的介绍，在互联网中有很多网页的内容是一样的，但是它们的网页元素却不是完全相同的。每个域名下的网页总会有一些自己的东西，比如广告、导航栏、网站版权之类的东西，但是对于搜索引擎来讲，只有内容部分才是有意义的，虽然网页元素不同，但是对搜索结果没有任何影响，所以在判定内容是否重复的时候，应该忽视后面的部分。当新爬取的内容和数据库中的某个网页的内容一样的时候，就称其为Near-Duplicates（重复文章）。对于重复文章，不应再执行入库操作，这种操作的优点是(A)节省带宽、(B)节省磁盘、(C)减轻服务器负荷以及(D)去除相似文章噪点干扰，提升索引的质量。","text":"Simhash的生成及存储 一、背景介绍 根据 Detecting Near-Duplicates for Web Crawling 论文中的介绍，在互联网中有很多网页的内容是一样的，但是它们的网页元素却不是完全相同的。每个域名下的网页总会有一些自己的东西，比如广告、导航栏、网站版权之类的东西，但是对于搜索引擎来讲，只有内容部分才是有意义的，虽然网页元素不同，但是对搜索结果没有任何影响，所以在判定内容是否重复的时候，应该忽视后面的部分。当新爬取的内容和数据库中的某个网页的内容一样的时候，就称其为Near-Duplicates（重复文章）。对于重复文章，不应再执行入库操作，这种操作的优点是(A)节省带宽、(B)节省磁盘、(C)减轻服务器负荷以及(D)去除相似文章噪点干扰，提升索引的质量。 在现实中，一模一样的网页的概率是很小的，大部分的相似网页都会存在一些细节的变化，而如何进行这种判定就是一个本文要解决的一个问题。除了近似文章判定算法的难题，还有以下待解决的难点（按照80亿篇文章来考虑）： 数据规模巨大，对于海量数据如何存储 查找速度，如何做到在毫秒级别返回检索结果 二、simhash介绍 simhash是由 Charikar 在2002年提出来的，它是一种能计算文档相似度的hash算法，google用它来进行海量文本去重工作。simhash属于局部敏感型（locality sensitive hash）的一种，其主要思想是降维，将高维的特征向量转化成一个f位的指纹（fingerprint），通过算出两个指纹的海明距离（hamming distince）来确定两篇文章的相似度，海明距离越小，相似度越低（根据 Detecting Near-Duplicates for Web Crawling 论文中所说），一般海明距离为3就代表两篇文章相同。 simhash也有其局限性，在处理小于500字的短文本时，simhash的表现并不是很好，所以在使用simhash前一定要注意这个细节。 三、simhash与hash算法的区别 传统Hash算法只负责将原始内容尽量均匀随机地映射为一个签名值，原理上仅相当于伪随机数产生算法。传统hash算法产生的两个签名，如果不相等，除了说明原始内容不相等外，不再提供任何信息，因为即使原始内容只相差一个字节，所产生的签名也很可能差别很大，所以传统Hash是无法在签名的维度上来衡量原内容的相似度。而SimHash本身属于一种局部敏感哈希算法，它产生的hash签名在一定程度上可以表征原内容的相似度。 我们主要解决的是文本相似度计算，要比较的是两个文章是否相似，当然我们降维生成了hash签名也是用于这个目的。看到这里，估计大家就明白了，即使把文章中的字符串变成 01 串，我们使用的simhash算法也还是可以用于计算相似度，而传统的hash却不行。我们可以来做个测试，两个相差只有一个字符的文本串，“你妈妈喊你回家吃饭哦，回家罗回家罗” 和 “你妈妈叫你回家吃饭啦，回家罗回家罗”。 通过simhash计算结果为： 1000010010101101111111100000101011010001001111100001001011001011 1000010010101101011111100000101011010001001111100001101010001011 通过传统hash计算为： 0001000001100110100111011011110 1010010001111111110010110011101 大家可以看得出来，相似的文本只有部分 01 串变化了，而普通的hash却不能做到，这个就是局部敏感哈希的魅力。 四、simhash的生成 simhash的生成图解如下图： 为了更加通俗易懂，采用例子来详解simhash的生成规则。simhash的生成划分为五个步骤：分词-&gt;hash-&gt;加权-&gt;合并-&gt;降维 1：分词。首先，判断文本分词，形成这个文章的特征单词。然后，形成去掉噪音词的单词序列。最后，为每个分词加上权重。我们假设权重分为5个级别（1~5），比如：“ 美国“51区”雇员称内部有9架飞碟，曾看见灰色外星人 ” ==&gt; 分词后为 “ 美国（4） 51区（5） 雇员（3） 称（1） 内部（2） 有（1） 9架（3） 飞碟（5） 曾（1） 看见（3） 灰色（4） 外星人（5）”，括号里是代表单词在整个句子里重要程度，数字越大越重要。 2：hash。通过hash算法把每个词变成hash值，比如“美国”通过hash算法计算为 100101，“51区”通过hash算法计算为 101011。这样，我们的字符串就变成了一串串数字，还记得文章开头说过的吗？要把文章变为数字计算，才能提高相似度计算性能，现在是降维过程进行时。 3：加权。在第2步骤hash生成结果后，需要按照单词的权重形成加权数字串，比如“美国”的hash值为“100101”，通过加权计算为“4 -4 -4 4 -4 4”；“51区”的hash值为“101011”，通过加权计算为 “ 5 -5 5 -5 5 5”。 4：合并。把上面各个单词算出来的序列值累加，变成只有一个序列串。比如 “美国”的 “4 -4 -4 4 -4 4”，“51区”的 “ 5 -5 5 -5 5 5”， 把每一位进行累加， “4+5 -4+-5 -4+5 4+-5 -4+5 4+5” ==》 “9 -9 1 -1 1 9”。这里作为示例只算了两个单词的，真实的计算需要把所有单词的序列串累加。 5：降维。把第4步算出来的 “9 -9 1 -1 1 9” 变成 0 1 串，形成我们最终的simhash签名。 如果每一位大于0 记为 1，小于或等于0 则记为 0。最后算出结果为：“1 0 1 0 1 1”。 整个过程的流程图为： 五、simhash分表存储策略 在线上查询算法中，首先建立多个指纹表:T1，T2，√…，Tt。每个指纹表 Ti 关联两个未知数：一个整型pi和一个在f bit-positions上的排列πi，Ti就是对已经存在的所有指纹进行排列πi得到的有序集合。对于一个指纹f和一个整数k，算法分两个步骤： 1 找到Ti中所有的前pi个bit-positions和πi（F）的前pi个bit-positions相同的指纹，假设为指纹集合F。 2 在F中的每一个指纹，比较其是否和πi（F）有的差异不超过k个。 分表存储原理 借鉴“hashmap算法找出可以hash的key值”。因为我们使用的simhash是局部敏感哈希，这个算法的特点是：只要相似的字符串，只有个别的位数是有差别变化的。这样，我们可以推断两个相似的文本，至少有16位的simhash是一样的。 分表存储设计 假设f = 64 ，k=3，并且我们有80亿 = 2^34个数的网页指纹，d=34，可以有下面四种设计方法 （f：指纹位数，k：海明距离，d：将文章数量转化成2的幂次方，d就是幂值） 1.20个表：将64bit分为11,11,11,11,10,10六个bit块。根据排列组合，如果想从这6个块中找3个作为leading bits的话（这样才能满足|pi-d|是个小整数），一共有C(6,3)=20种找法，所以需要20个表，每个表的前三块来自不同的三个块，那么pi就有11+11+11、11+ 11+10和11+10+10三种可能了。一次嗅探平均需要检索2^(34-31)=8个指纹。 2.16个表：先将64bit均分成4份，然后针对每份，将剩余的48bit再均分成四份，也就是16,12,12,12,12,12五部分，很明显这种组合的可能是4*4，而pi = 28。一次嗅探平均需要检索2^(34-28)=64个指纹。 3.10个表：将64bit分成 13，13，13，13，12 五个bit快。根据排列组合，需要从5块中找到2个作为leading bits，共有C(5,2)=10种找法，需要10张表，而pi=25或26。一次嗅探平均需要检索2^(34-25)=512个指纹。 4.4个表：同理 64 等分为4份，每份16bit，从四份中找出1个leading bits，共有C(4,1)=4种找法，pi=16,一次嗅探平均需要检索2^(34-16)=256K个指纹。 分表存储实现 存储： 1、将一个64位的simhash签名拆分成4个16位的二进制码。（图上红色的16位） 2、分别拿这4个16位二进制码查找当前对应位置上是否有元素。（放大后的16位） 3、对应位置没有元素，直接追加到链表上；对应位置有则直接追加到链表尾端。（图上的 S1 — SN） 查找： 1、将需要比较的simhash签名拆分成4个16位的二进制码。 2、分别拿着4个16位二进制码每一个去查找simhash集合对应位置上是否有元素。 3、如果有元素，则把链表拿出来顺序查找比较，直到simhash小于一定大小的值，整个过程完成。 原理： 借鉴“hashmap算法找出可以hash的key值”。因为我们使用的simhash是局部敏感哈希，这个算法的特点是：只要相似的字符串，只有个别的位数是有差别变化的。那这样我们可以推断两个相似的文本，至少有16位的simhash是一样的。具体选择16位、8位、4位，大家根据自己的数据测试选择，虽然比较的位数越小越精准，但是空间会变大。分为4个16位段的存储空间是单独simhash存储空间的4倍。之前算出5000w数据是 382 Mb，扩大4倍1.5G左右，还可以接受 最佳分表策略 根据 4.2节分表存储设计，给定 f,k 我们可以有很多种分表的方式，增加表的个数会减少检索时间，但是会增加内存的消耗，相反的，减少表的个数，会减少内存的压力，但是会增加检索时间。 根据google大量的实验，存在一个分表策略满足时间和空间的平衡点 τ=d-pi （pi计算看4.2章节，取最小pi） simhash存储实现(Go) 国外有一大神用go实现了d=3和6的实现，在他的基础上我实现了d到8的扩展，源码请看https://github.com/kricen/shstorage 参考文章 论文 Detecting Near-Duplicates for Web Crawling http://www.cnblogs.com/maybe2030/p/5203186.html 原文链接：https://kricen.github.io/2018/03/06/perday/simhash/","categories":[],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"http://yoursite.com/tags/algorithm/"}]},{"title":"如何使用 Disruptor（三）","slug":"disruptor3","date":"2019-11-18T12:03:12.000Z","updated":"2019-11-19T00:50:59.661Z","comments":true,"path":"2019/11/18/disruptor3/","link":"","permalink":"http://yoursite.com/2019/11/18/disruptor3/","excerpt":"写入 Ringbuffer 本文的重点是：不要让 Ring 重叠；如何通知消费者；生产者一端的批处理；以及多个生产者如何协同工作。 作者：Trisha 廖涵译 这是 Disruptor 全方位解析（end-to-end view）中缺少的一章。当心，本文非常长。但是为了让你能联系上下文阅读，我还是决定把它们写进一篇博客里。","text":"写入 Ringbuffer 本文的重点是：不要让 Ring 重叠；如何通知消费者；生产者一端的批处理；以及多个生产者如何协同工作。 作者：Trisha 廖涵译 这是 Disruptor 全方位解析（end-to-end view）中缺少的一章。当心，本文非常长。但是为了让你能联系上下文阅读，我还是决定把它们写进一篇博客里。 本文的 重点 是：不要让 Ring 重叠；如何通知消费者；生产者一端的批处理；以及多个生产者如何协同工作。 ProducerBarriers Disruptor 代码 给 消费者 提供了一些接口和辅助类，但是没有给写入 Ring Buffer 的 生产者 提供接口。这是因为除了你需要知道生产者之外，没有别人需要访问它。尽管如此，Ring Buffer 还是与消费端一样提供了一个 ProducerBarrier 对象，让生产者通过它来写入 Ring Buffer。 写入 Ring Buffer 的过程涉及到两阶段提交 (two-phase commit)。首先，你的生产者需要申请 buffer 里的下一个节点。然后，当生产者向节点写完数据，它将会调用 ProducerBarrier 的 commit 方法。 那么让我们首先来看看第一步。 “给我 Ring Buffer 里的下一个节点”，这句话听起来很简单。的确，从生产者角度来看它很简单：简单地调用 ProducerBarrier 的 nextEntry() 方法，这样会返回给你一个 Entry 对象，这个对象就是 Ring Buffer 的下一个节点。 ProducerBarrier 如何防止 Ring Buffer 重叠 在后台，由 ProducerBarrier 负责所有的交互细节来从 Ring Buffer 中找到下一个节点，然后才允许生产者向它写入数据。 （我不确定 闪闪发亮的新手写板 能否有助于提高我画图片的清晰度，但是它用起来很有意思）。 在这幅图中，我们假设只有一个生产者写入 Ring Buffer。过一会儿我们再处理多个生产者的复杂问题。 ConsumerTrackingProducerBarrier 对象拥有所有正在访问 Ring Buffer 的 消费者 列 表。这看起来有点儿奇怪－我从没有期望 ProducerBarrier 了解任何有关消费端那边的事情。但是等等，这是有原因的。因为我们不想与队列“混为一谈”（队列需要追踪队列的头和尾，它们有时候会指向相同的位 置），Disruptor 由消费者负责通知它们处理到了哪个序列号，而不是 Ring Buffer。所以，如果我们想确定我们没有让 Ring Buffer 重叠，需要检查所有的消费者们都读到了哪里。 在上图中，有一个 消费者 顺利的读到了最大序号 12（用红色/粉色高亮）。第二个消费者 有点儿落后——可能它在做 I/O 操作之类的——它停在序号 3。因此消费者 2 在赶上消费者 1 之前要跑完整个 Ring Buffer 一圈的距离。 现在生产者想要写入 Ring Buffer 中序号 3 占据的节点，因为它是 Ring Buffer 当前游标的下一个节点。但是 ProducerBarrier 明白现在不能写入，因为有一个消费者正在占用它。所以，ProducerBarrier 停下来自旋 (spins)，等待，直到那个消费者离开。 申请下一个节点 现在可以想像消费者 2 已经处理完了一批节点，并且向前移动了它的序号。可能它挪到了序号 9（因为消费端的批处理方式，现实中我会预计它到达 12，但那样的话这个例子就不够有趣了）。 上图显示了当消费者 2 挪动到序号 9 时发生的情况。在这张图中我已经忽略了ConsumerBarrier，因为它没有参与这个场景。 ProducerBarier 会看到下一个节点——序号 3 那个已经可以用了。它会抢占这个节点上的 Entry（我还没有特别介绍 Entry 对象，基本上它是一个放写入到某个序号的 Ring Buffer 数据的桶），把下一个序号（13）更新成 Entry 的序号，然后把 Entry 返回给生产者。生产者可以接着往 Entry 里写入数据。 提交新的数据 两阶段提交的第二步是——对，提交。 绿色表示最近写入的 Entry，序号是 13 ——厄，抱歉，我也是红绿色盲。但是其他颜色甚至更糟糕。 当生产者结束向 Entry 写入数据后，它会要求 ProducerBarrier 提交。 ProducerBarrier 先等待 Ring Buffer 的游标追上当前的位置（对于单生产者这毫无意义－比如，我们已经知道游标到了 12 ，而且没有其他人正在写入 Ring Buffer）。然后 ProducerBarrier 更新 Ring Buffer 的游标到刚才写入的 Entry 序号－在我们这儿是 13。接下来，ProducerBarrier 会让消费者知道 buffer 中有新东西了。它戳一下 ConsumerBarrier 上的 WaitStrategy 对象说－“喂，醒醒！有事情发生了！”（注意－不同的 WaitStrategy 实现以不同的方式来实现提醒，取决于它是否采用阻塞模式。） 现在消费者 1 可以读 Entry 13 的数据，消费者 2 可以读 Entry 13 以及前面的所有数据，然后它们都过得很 happy。 ProducerBarrier 上的批处理 有趣的是 Disruptor 可以同时在生产者和 消费者 两端实现批处理。还记得伴随着程序运行，消费者 2 最后达到了序号 9 吗？ProducerBarrier 可以在这里做一件很狡猾的事－它知道 Ring Buffer 的大小，也知道最慢的消费者位置。因此它能够发现当前有哪些节点是可用的。 如果 ProducerBarrier 知道 Ring Buffer 的游标指向 12，而最慢的消费者在 9 的位置，它就可以让生产者写入节点 3，4，5，6，7 和 8，中间不需要再次检查消费者的位置。 多个生产者的场景 到这里你也许会以为我讲完了，但其实还有一些细节。 在上面的图中我稍微撒了个谎。我暗示了 ProducerBarrier 拿到的序号直接来自 Ring Buffer 的游标。然而，如果你看过代码的话，你会发现它是通过 ClaimStrategy 获取的。我省略这个对象是为了简化示意图，在单个生产者的情况下它不是很重要。 在多个生产者的场景下，你还需要其他东西来追踪序号。这个序号是指当前可写入的序号。注意这和“向 Ring Buffer 的游标加 1”不一样－如果你有一个以上的生产者同时在向 Ring Buffer 写入，就有可能出现某些 Entry 正在被生产者写入但还没有提交的情况。 让我们复习一下如何申请写入节点。每个生产者都向 ClaimStrategy 申请下一个可用的节点。生产者 1 拿到序号 13，这和上面单个生产者的情况一样。生产者 2 拿到序号 14，尽管 Ring Buffer的当前游标仅仅指向 12。这是因为 ClaimSequence 不但负责分发序号，而且负责跟踪哪些序号已经被分配。 现在每个生产者都拥有自己的写入节点和一个崭新的序号。 我把生产者 1 和它的写入节点涂上绿色，把生产者 2 和它的写入节点涂上可疑的粉色－看起来像紫色。 现在假设生产者 1 还生活在童话里，因为某些原因没有来得及提交数据。生产者 2 已经准备好提交了，并且向 ProducerBarrier 发出了请求。 就像我们先前在 commit 示意图中看到的一样，ProducerBarrier 只有在 Ring Buffer 游标到达准备提交的节点的前一个节点时它才会提交。在当前情况下，游标必须先到达序号 13 我们才能提交节点 14 的数据。但是我们不能这样做，因为生产者 1 正盯着一些闪闪发光的东西，还没来得及提交。因此 ClaimStrategy 就停在那儿自旋 (spins)， 直到 Ring Buffer 游标到达它应该在的位置。 现在生产者 1 从迷糊中清醒过来并且申请提交节点 13 的数据（生产者 1 发出的绿色箭头代表这个请求）。ProducerBarrier 让 ClaimStrategy 先等待 Ring Buffer 的游标到达序号 12，当然现在已经到了。因此 Ring Buffer 移动游标到 13，让 ProducerBarrier 戳一下 WaitStrategy 告诉所有人都知道 Ring Buffer 有更新了。现在 ProducerBarrier 可以完成生产者 2 的请求，让 Ring Buffer 移动游标到 14，并且通知所有人都知道。 你会看到，尽管生产者在不同的时间完成数据写入，但是 Ring Buffer 的内容顺序总是会遵循 nextEntry() 的初始调用顺序。也就是说，如果一个生产者在写入 Ring Buffer 的时候暂停了，只有当它解除暂停后，其他等待中的提交才会立即执行。 呼——。我终于设法讲完了这一切的内容并且一次也没有提到内存屏障（Memory Barrier）。 更新：最近的 RingBuffer 版本去掉了 Producer Barrier。如果在你看的代码里找不到 ProducerBarrier，那就假设当我讲“Producer Barrier”时，我的意思是“Ring Buffer”。 更新2：注意 Disruptor 2.0 版使用了与本文不一样的命名。如果你对类名感到困惑，请阅读我写的Disruptor 2.0更新摘要。 原文链接：http://ifeve.com/dissecting-the-disruptor-writing-to-the-ring-buffer/ 译文链接：http://ifeve.com/disruptor-writing-ringbuffer/","categories":[],"tags":[{"name":"concurrent","slug":"concurrent","permalink":"http://yoursite.com/tags/concurrent/"}]},{"title":"如何使用Disruptor（二）","slug":"disruptor2","date":"2019-11-18T11:57:31.000Z","updated":"2019-11-19T00:49:59.458Z","comments":true,"path":"2019/11/18/disruptor2/","link":"","permalink":"http://yoursite.com/2019/11/18/disruptor2/","excerpt":"从Ringbuffer读取数据 从上一篇文章中我们都了解了什么是Ring Buffer以及它是如何的特别。但遗憾的是，我还没有讲述如何使用Disruptor向Ring Buffer写数据和从Ring Buffer中读取数据。 从上一篇文章中我们都了解了什么是Ring Buffer以及它是如何的特别。但遗憾的是，我还没有讲述如何使用Disruptor向Ring Buffer写数据和从Ring Buffer中读取数据。","text":"从Ringbuffer读取数据 从上一篇文章中我们都了解了什么是Ring Buffer以及它是如何的特别。但遗憾的是，我还没有讲述如何使用Disruptor向Ring Buffer写数据和从Ring Buffer中读取数据。 从上一篇文章中我们都了解了什么是Ring Buffer以及它是如何的特别。但遗憾的是，我还没有讲述如何使用Disruptor向Ring Buffer写数据和从Ring Buffer中读取数据。 ConsumerBarrier与消费者 这里我要稍微反过来介绍，因为总的来说读取数据这一过程比写数据要容易理解。假设通过一些“魔法”已经把数据写入到Ring Buffer了，怎样从Ring Buffer读出这些数据呢？ (好，我开始后悔使用Paint/Gimp 了。尽管这是个购买绘图板的好借口，如果我继续写下去的话… UML界的权威们大概也在诅咒我的名字了。) 消费者(Consumer)是一个想从Ring Buffer里读取数据的线程，它可以访问ConsumerBarrier对象——这个对象由RingBuffer创建并且代表消费者与RingBuffer进行交互。就像Ring Buffer显然需要一个序号才能找到下一个可用节点一样，消费者也需要知道它将要处理的序号——每个消费者都需要找到下一个它要访问的序号。在上面的例子中，消费者处理完了Ring Buffer里序号8之前（包括8）的所有数据，那么它期待访问的下一个序号是9。 消费者可以调用ConsumerBarrier对象的waitFor()方法，传递它所需要的下一个序号. 1final long availableSeq = consumerBarrier.waitFor(nextSequence); ConsumerBarrier返回RingBuffer的最大可访问序号——在上面的例子中是12。ConsumerBarrier有一个WaitStrategy方法来决定它如何等待这个序号，我现在不会去描述它的细节，代码的注释里已经概括了每一种WaitStrategy的优点和缺点 。 接下来怎么做？ 接下来，消费者会一直原地停留，等待更多数据被写入Ring Buffer。并且，一旦数据写入后消费者会收到通知——节点9，10，11和12 已写入。现在序号12到了，消费者可以让ConsumerBarrier去拿这些序号节点里的数据了。 拿到了数据后，消费者(Consumer)会更新自己的标识(cursor)。 你应该已经感觉得到，这样做是怎样有助于平缓延迟的峰值了——以前需要逐个节点地询问“我可以拿下一个数据吗？现在可以了么？现在呢？”，消费者(Consumer)现在只需要简单的说“当你拿到的数字比我这个要大的时候请告诉我”，函数返回值会告诉它有多少个新的节点可以读取数据了。因为这些新的节点的确已经写入了数据（Ring Buffer本身的序号已经更新），而且消费者对这些节点的唯一操作是读而不是写，因此访问不用加锁。这太好了，不仅代码实现起来可以更加安全和简单，而且不用加锁使得速度更快。 另一个好处是——你可以用多个消费者(Consumer)去读同一个RingBuffer ，不需要加锁，也不需要用另外的队列来协调不同的线程(消费者)。这样你可以在Disruptor的协调下实现真正的并发数据处理。 BatchConsumer代码是一个消费者的例子。如果你实现了BatchHandler, 你可以用BatchConsumer来完成上面我提到的复杂工作。它很容易对付那些需要成批处理的节点（例如上文中要处理的9-12节点）而不用单独地去读取每一个节点。 更新：注意Disruptor 2.0版本使用了与本文不一样的命名。如果你对类名感到困惑，请阅读我的变更总结。 原文链接：http://ifeve.com/dissecting-the-disruptor-how-do-i-read-from-the-ring-buffer/ 译文链接：http://ifeve.com/dissecting_the_disruptor_how_doi_read_from_the_ring_buffer/","categories":[],"tags":[{"name":"concurrent","slug":"concurrent","permalink":"http://yoursite.com/tags/concurrent/"}]},{"title":"如何使用Disruptor（一）","slug":"disruptor1","date":"2019-11-18T11:35:08.000Z","updated":"2019-11-19T00:49:31.187Z","comments":true,"path":"2019/11/18/disruptor1/","link":"","permalink":"http://yoursite.com/2019/11/18/disruptor1/","excerpt":"Ringbuffer的特别之处 首先介绍ringbuffer。我对Disruptor的最初印象就是ringbuffer。但是后来我意识到尽管ringbuffer是整个模式（Disruptor）的核心，但是Disruptor对ringbuffer的访问控制策略才是真正的关键点所在。 作者：Trisha 寒桐译 最近，我们开源了LMAX Disruptor， 它是我们的交易系统吞吐量快（LMAX是一个新型的交易平台，","text":"Ringbuffer的特别之处 首先介绍ringbuffer。我对Disruptor的最初印象就是ringbuffer。但是后来我意识到尽管ringbuffer是整个模式（Disruptor）的核心，但是Disruptor对ringbuffer的访问控制策略才是真正的关键点所在。 作者：Trisha 寒桐译 最近，我们开源了LMAX Disruptor， 它是我们的交易系统吞吐量快（LMAX是一个新型的交易平台， 号称能够单线程每秒处理数百万的订单）的关键原因。为什么我们要将其开源？我们意识到对高性能编程领域的一些传统观点，有点不对劲。我们找到了一种更好、更快地在线程间共享数据的方法，如果不公开于业界共享的话，那未免太自私了。同时开源也让我 们觉得看起来更酷。 从这个站点，你可以下载到一篇解释什么是Disruptor及它为什么如此高性能的文档。这篇文档的编写过程，我并没有参与太多，只是简单地插入了一些标点符号和重组了一些我不懂的句子，但是非常高兴的是，我仍然从中提升了自己的写作水平。 我发现要把所有的事情一下子全部解释清楚还是有点困难的，所有我准备一部分一部分地解释它们，以适合我的NADD听众。 首先介绍ringbuffer。我对Disruptor的最初印象就是ringbuffer。但是后来我意识到尽管ringbuffer是整个模式（Disruptor）的核心，但是Disruptor对ringbuffer的访问控制策略才是真正的关键点所在。 ringbuffer到底是什么？ 嗯，正如名字所说的一样，它是一个环（首尾相接的环），你可以把它用做在不同上下文（线程）间传递数据的buffer。 （好吧，这是我通过画图板手画的，我试着画草图，希望我的强迫症不会让我画完美的圆和直线） 基本来说，ringbuffer拥有一个序号，这个序号指向数组中下一个可用的元素。（校对注：如下图右边的图片表示序号，这个序号指向数组的索引4的位置。） 随着你不停地填充这个buffer（可能也会有相应的读取），这个序号会一直增长，直到绕过这个环。 要找到数组中当前序号指向的元素，可以通过mod操作： sequence mod array length = array index 以上面的ringbuffer为例（java的mod语法）：12 % 10 = 2。很简单吧。 事实上，上图中的ringbuffer只有10个槽完全是个意外。如果槽的个数是2的N次方更有利于基于二进制的计算机进行计算。 （校对注：2的N次方换成二进制就是1000，100，10，1这样的数字， sequence &amp; （array length－1） = array index，比如一共有8槽，3&amp;（8－1）=3，HashMap就是用这个方式来定位数组元素的，这种方式比取模的速度更快。） 那又怎么样？ 如果你看了维基百科里面的关于环形buffer的 词条，你就会发现，我们的实现方式，与其最大的区别在于：没有尾指针。我们只维护了一个指向下一个可用位置的序号。这种实现是经过深思熟虑的—我们选择用 环形buffer的最初原因就是想要提供可靠的消息传递。我们需要将已经被服务发送过的消息保存起来，这样当另外一个服务通过nak (校对注：拒绝应答信号)告诉我们没有成功收到消息时，我们能够重新发送给他们。 听起来，环形buffer非常适合这个场景。它维护了一个指向尾部的序号，当收到nak(校对注：拒绝应答信号)请求，可以重发从那一点到当前序号之间的所有消息： 我们实现的ring buffer和大家常用的队列之间的区别是，我们不删除buffer中的数据，也就是说这些数据一直存放在buffer中，直到新的数据覆盖他们。这就是 和维基百科版本相比，我们不需要尾指针的原因。ringbuffer本身并不控制是否需要重叠（决定是否重叠是生产者-消费者行为模式的一部分–如果你等 不急我写blog来说明它们，那么可以自行检出Disruptor项目）。 它为什么如此优秀？ 之所以ringbuffer采用这种数据结构，是因为它在可靠消息传递方面有很好的性能。这就够了，不过它还有一些其他的优点。 首先，因为它是数组，所以要比链表快，而且有一个容易预测的访问模式。（译者注：数组内元素的内存地址的连续性存储的）。这是对CPU缓存友好的—也就是说，在硬件级别，数组中的元素是会被预加载的，因此在ringbuffer当中，cpu无需时不时去主存加载数组中的下一个元素。（校对注：因为只要一个元素被加载到缓存行，其他相邻的几个元素也会被加载进同一个缓存行） 其次，你可以为数组预先分配内存，使得数组对象一直存在（除非程序终止）。这就意味着不需要花大量的时间用于垃圾回收。此外，不像链表那样，需要为每一个添加到其上面的对象创造节点对象—对应的，当删除节点时，需要执行相应的内存清理操作。 缺少的部分 我并没有在本文中介绍如何避免ringbuffer产生重叠，以及如何对ringbuffer进行读写操作。你可能注意到了我将ringbuffer和链表那样的数据结构进行比较，因为我并认为链表是实际问题的标准答案。 当你将Disruptor和基于 队列之类的实现进行比较时，事情将变得很有趣。队列通常注重维护队列的头尾元素，添加和删除元素等。所有的这些我都没有在ringbuffer里提到，这 是因为ringbuffer不负责这些事情，我们把这些操作都移到了数据结构（ringbuffer）的外部 原文链接：http://ifeve.com/ringbuffer/ 译文链接：http://ifeve.com/dissecting-disruptor-whats-so-special/","categories":[],"tags":[{"name":"concurrent","slug":"concurrent","permalink":"http://yoursite.com/tags/concurrent/"}]},{"title":"TF-IDF算法介绍","slug":"TF-IDF","date":"2019-11-18T11:14:08.000Z","updated":"2019-11-19T00:55:01.350Z","comments":true,"path":"2019/11/18/TF-IDF/","link":"","permalink":"http://yoursite.com/2019/11/18/TF-IDF/","excerpt":"TF-IDF是什么 TF-IDF是一种统计方法，用以评估一个词对于一篇文章或语料库中一篇文章的重要性。字词的重要性随着它在文件中出现的次数成正比增加，但同时会随着它在语料库中出现的频率成反比下降。 TF-IDF的使用场景 TF-IDF加权的各种形式常被搜索引擎应用，作为文件与用户查询之间相关程度的度量或评级。除了TF-IDF以外，因特网上的搜索引擎还会使用基于链接分析的评级方法，以确定文件在搜寻结果中出现的顺序。","text":"TF-IDF是什么 TF-IDF是一种统计方法，用以评估一个词对于一篇文章或语料库中一篇文章的重要性。字词的重要性随着它在文件中出现的次数成正比增加，但同时会随着它在语料库中出现的频率成反比下降。 TF-IDF的使用场景 TF-IDF加权的各种形式常被搜索引擎应用，作为文件与用户查询之间相关程度的度量或评级。除了TF-IDF以外，因特网上的搜索引擎还会使用基于链接分析的评级方法，以确定文件在搜寻结果中出现的顺序。 TF-IDF原理 TF（Term Frequency) 表示词频，即一个词在在一篇文章中出现的次数，但在实际应用时会有一个漏洞，就是篇幅长的文章给定词出现的次数会更多一点。因此我们需要对次数进行归一化，通常用给定词的次数除以文章的总词数。 这其中还有一个漏洞，就是 ”的“ ”是“ ”啊“ 等类似的词在文章中出现的此时是非常多的，但是这些大多都是没有意义词，对于判断文章的关键词几乎没有什么用处，我们称这些词为”停用词“，也就是说，在度量相关性的时候不应该考虑这些词的频率。 IDF（Inverse Document Frequency）逆文本频率指数，如果包含关键词w的文档越少，则说明关键词w具有很好的类别区分能力。某一关键词的IDF，可以用总的文章数量除以包含该关键词的文章的数量，然后对结果取对数得到 注：分母加1是为了避免没有包含关键词的文章时分母是0的情况 一个词预测主题的能力越强，权重就越大，反之，权重越小，因此一个词的TF-IDF就是： 实际应用 通常在新闻的分类，或者说文章的分类的时候我们会用到ID-IDF。如果让编辑来对新闻或者文章分类，他一定要先读懂文章，然后找出主题，最后根据主题的不同对文章进行分类。而让电脑对文章进行分类，就要求我们先把文字的文章变成一组可以计算的数字，然后通过算法来算出文章的相似性。 首先我们先来看怎么用一组数字（或者说一个向量）来表示一篇文章。对于一篇文章的所有实词（除去无意义的停用词），计算出他们的TF-IDF值，把这些值按照对应的实词在词汇表的位置依次排列，就得到了一个向量。比如，词汇表中有64000个词，其编号和词： 单词编号 汉字词 1 阿 2 啊 … … 789 服装 … … 64000 做作 在某一篇文章中，文章中的词的TF-IDF值对应为： 单词编号 TF-IDF 1 0 2 0.0034 … … 789 0.034 … … 64000 0.075 如果单词表的某个词在文章中没有出现，对应的值为零，这样我们就得到了一个64000维的向量，我们称为这篇文章的特征向量。然后每篇文章就可以用一个向量来表示，这样我们就可以计算文章之间的相似程度了。 向量的夹角是衡量两个向量相近程度的度量。因此，可以通过计算两篇文章的特征向量的夹角来判断两篇文章的主题的接近程度。那么我们就需要用余弦地理了。 ∠A的余弦值为： 如果将三角形的两边b和c看成是两个以A为起点的向量，那么上述公式等于： 其中，分母便是两个向量b和c的长度，分子表示两个向量的内积。假设文章X和文章Y对应的向量是 那么他们的夹角的余弦等于 由于向量中的每一个变量都是正数，所以余弦的取值在0到1之间。当两篇文章向量的余弦等于1时，这两个向量夹角为零，两篇文章完全相同；当夹角的余弦接近于1时两篇文章越相似，从而可以归成一类；夹角的余弦越小，夹角越大，两篇文章越不相关。 现在假定我们已知一些文章的特征向量，那么对于任何一个要被分类的文章，就很容易计算出它和各类文章的余弦相似性，并将其归入它该去的那一类中。 如果事先没有已知的文章的特征向量呢，可以用自底向上不断合并的方法。 计算所有文章之间凉凉的余弦相似性，把相似性大于一个阈值的合并成一小类 把每个小类中的所有文章作为一个整体，计算小类的特征向量，在计算小雷之间两两的余弦相似性，然后合并成一个大类 这样不断做下去，类别越来越少，而每个类越来越大。当某一类太大时，这一类里的文章的相似性就很小了，这时就要停止迭代过程了，然后完成分类。","categories":[],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"http://yoursite.com/tags/algorithm/"}]},{"title":"工具网站收藏","slug":"useful-website","date":"2019-11-18T08:28:03.000Z","updated":"2019-11-19T00:55:23.613Z","comments":true,"path":"2019/11/18/useful-website/","link":"","permalink":"http://yoursite.com/2019/11/18/useful-website/","excerpt":"Part1:前端工具 【1】字体图标生成网站：IconMoon：https://icomoon.io/ 【2】reset 和 globle CSS：https://meyerweb.com/eric/tools/css/reset/ 【3】阿里巴巴矢量图标库：https://www.iconfont.cn/","text":"Part1:前端工具 【1】字体图标生成网站：IconMoon：https://icomoon.io/ 【2】reset 和 globle CSS：https://meyerweb.com/eric/tools/css/reset/ 【3】阿里巴巴矢量图标库：https://www.iconfont.cn/ 【4】EChart：https://echarts.baidu.com/ 【5】iView：https://www.iviewui.com/ Part2:视频教程 【1】慕课网：https://www.imooc.com/ 【2】Siki学院：http://www.sikiedu.com/ 【3】Bilibili：https://www.bilibili.com/ Part3:实用网站 【1】国家哲学社会科学文献中心：http://www.ncpssd.org 【2】MSDN，我告诉你： https://msdn.itellyou.cn/","categories":[],"tags":[{"name":"tools","slug":"tools","permalink":"http://yoursite.com/tags/tools/"}]},{"title":"树莓派镜像制作","slug":"raspberry-blog1","date":"2019-11-18T05:21:43.000Z","updated":"2019-11-19T00:51:45.808Z","comments":true,"path":"2019/11/18/raspberry-blog1/","link":"","permalink":"http://yoursite.com/2019/11/18/raspberry-blog1/","excerpt":"【1】树莓派原始镜像烧录。 【2】中文字库以及中文拼音输入法下载： 启动后，开启Terminal终端，出现提示符时输入： 1sudo apt-get install ttf-wqy-zenhei","text":"【1】树莓派原始镜像烧录。 【2】中文字库以及中文拼音输入法下载： 启动后，开启Terminal终端，出现提示符时输入： 1sudo apt-get install ttf-wqy-zenhei 将安装文泉驿的开源中文字体，在这里向文泉驿表示致敬，貌似它是唯一一个开源的中文字体库。郭嘉有钱建孔子学院，但是从来不会有钱搞一套比较完整的开源中文字库出来的。 中文是可以显示啦，输入呢？Linux下早就有啦，叫SCIM（Smart Common Input Method ），所以只要输入： 1sudo apt-get install scim-pinyin 就会安装拼音输入法，安装完成后，可以直接打入scim激活，下次启动是会自动启动的。快捷键也是Ctrl+空格。或者直接点击右下角图标选择。 接着运行： 1sudo raspi-config 然后选择change_locale，在Default locale for the system environment:中选择zh_CN.UTF-8。然后重启机器，就发现整个环境变成中文的了。 【3】安装 Pi4j： Installation Easy/Preferred (NOTE: This installation method requires that your RaspberryPi is connected to the Internet.) The simplest method to install Pi4J on your RaspberryPi is to execute the following command directly on your RaspberryPi. 1curl -s get.pi4j.com | sudo bash This method will download and launch an installation script that perform the following steps: adds the Pi4J APT repository to the local APT repositories downloads and installs the Pi4J GPG public key for signature validation invokes the ‘apt-get update’ command on the Pi4J APT repository to update the local package database invokes the ‘apt-get install pi4j’ command to perform the download and installation Offline/Manual If you prefer/need to install Pi4J on a RaspberryPi device without an Internet connection, the following instructions provide the steps necessary to install Pi4J without requiring an Internet connection. First, download a copy of the latest Pi4J Debian/Raspian installer package (.deb) file to your local computer. You can download the Pi4J Debian/Raspian installer package (.deb) using your web browser at the following URL: http://get.pi4j.com/download/pi4j-1.2-SNAPSHOT.deb Next, you will need to transfer the download installer package over to your RaspberryPi. You can use any method you prefer to transfer the file (USB, SCP, FTP, etc.) (NOTE: If you have a previous version of Pi4J installed, you will need to uninstall it first.) Once the installer package is available on your RaspberryPi, use the following command on the Pi to perform the installation: 1sudo dpkg -i pi4j-1.2-SNAPSHOT.deb Upgrade Easy/Preferred If you originally installed Pi4J using the ‘easy’ method, then Pi4J upgrades will be available anytime you perform a system update using ‘sudo apt-get update’ and ‘sudo update-get upgrade’. If you wish to force an upgrade of the Pi4J package only, you can do so by executing the following command: 1sudo apt-get install pi4j or pi4j --update Offline/Manual If you originally installed Pi4J using the ‘offline’ method, then you will need to manually uninstall the Pi4J package and download, transfer, and install the new version package using the ‘offline’ uninstall and installation methods described here on this page. Uninstall Easy/Preferred If you originally installed Pi4J using the ‘easy’ method, then you can uninstall Pi4J simply by executing the following command on your RaspberryPi. 1sudo apt-get remove pi4j or pi4j --uninstall Complete/Full Removal If you originally installed Pi4J using the ‘easy’ method and you want to remove all traces of Pi4J, including the Pi4J repository in the APT repositories list and the Pi4J GPG signature, then simply execute the following command on your RaspberryPi. 1curl -s get.pi4j.com/uninstall | sudo bash Offline/Manual If you originally installed Pi4J using the ‘offline’ method, then you will need to manually uninstall the Pi4J package by executing the following command on your Raspberry Pi: 1sudo dpkg -r pi4j Installed Location / Example Files This will install the Pi4J libraries and example source files to: 12/opt/pi4j/lib /opt/pi4j/examples When attempting to compile a Java program using the Pi4J libraries, make sure to include the Pi4J lib folder in the classpath: 1javac -classpath .:classes:/opt/pi4j/lib/'*' ... When attempting to start a Java program using the Pi4J libraries, make sure to include the Pi4J lib folder in the classpath: 1sudo java -classpath .:classes:/opt/pi4j/lib/'*' ... If you would like to explore the examples, you can compile all the examples with the following commands: 1/opt/pi4j/examples/build Pi4j官网:https://pi4j.com 【4】安装 JavaFX 插件包： As you can read here, the most recent JDK versions for ARM don’t include JavaFX. If you want to use JavaFX in your Raspberry Pi, the solution is adding the missing JavaFX SDK. If you install the recent Oracle’s JDK for ARM from here (select jdk-8u111-linux-arm32-vfp-hflt.tar.gz), then you will need to download the JavaFX SDK from Gluon’s site (select JavaFX Embedded SDK for armv6 hard float). Once you have the file, unzip it, and copy the folders to your JDK. Assuming you have downloaded armv6hf-sdk-8.60.8.zip to your Pi/Downloads folder, and you have unzip it to a folder armv6hf-sdk, like in the following picture: using the following commands will allow you moving from command line the files to the JDK required folders. You can use a graphic tool for this as well. 12345678cd Downloads sudo chown -R root:root armv6hf-sdk cd armv6hf-sdk sudo mv lib/javafx-mx.jar /opt/jdk1.8.0_111/lib/ cd rt/lib/ sudo mv j* /opt/jdk1.8.0_111/jre/lib/ sudo mv arm/* /opt/jdk1.8.0_111/jre/lib/arm/ sudo mv ext/* /opt/jdk1.8.0_111/jre/lib/ext/ After that you should be able to run Java/JavaFX programs. 参考链接:https://stackoverflow.com/questions/40481455/running-javafx-gui-on-the-raspberry-pi/40483500#40483500 【5】解决树莓派图形渲染问题： JavaFX glGetError 0x505 You can try increase the available raspberry pi video memory using the sudo raspi-config tool. try change to the 50/50 memory spit. 参考链接:https://www.raspberrypi.org/forums/viewtopic.php?f=81&amp;t=60024#p448200 【6】树莓派播放视频： WebView and Media were never part of the JavaFX ARM distribution, but Gluon recently added it to the embedded SDK that can be downloaded from here and installed with a recent JDK for ARM, available here. Media requires a few extra steps as it depends in the native drivers that usually are not fully installed on a regular Jessie distribution. First install these drivers: 12sudo apt-get install gstreamer0.10-plugins-good sudo apt-get install gstreamer0.10-plugins-bad Now edit /etc/apt/sources.list and add at the end: 1deb http://ftp.uk.debian.org/debian/ wheezy main deb-src http://ftp.uk.debian.org/debian/ wheezy main Save the file (Ctrl+O, Ctrl+X). Finally update and install the drivers: 123sudo apt-get update sudo apt-get install gstreamer0.10-ffmpeg sudo apt-get install gstreamer0.10-alsa Now you can try to run again your JavaFX application. If you find again the same exception (MediaException: UNKNOWN), check if it shows this message: Error in GstPipelineFactory, notice the driver that is missing, and try to install it. 参考链接:https://stackoverflow.com/questions/42076680/play-a-video-using-javafx-on-raspberry-pi 【7】常用的设置树莓派自启动的方法： 这个方式不用修改 rc.local 文件。机制上类似于 Windows 的“开始”菜单中的“启动”菜单。方法如下： 在 /home/pi/.config 下创建一个文件夹，名称为 autostart，并在该文件夹下创建一个xxx.desktop文件（文件名以.desktop结尾，前面可以自定义），文件内容如下： 12345678910[Desktop Entry] Name=example Comment=My Python Program Exec=python /home/pi/example.py Icon=/home/pi/example.png Terminal=false MultipleArgs=false Type=Application Categories=Application;Development; StartupNotify=true 以上 Name、Comment、Icon 可以自定，分别表示这个启动项目的名称、备注以及显示的图标。Exec 表示调用的指令，和在终端输入运行脚本的指令格式一致。 参考链接：https://www.jianshu.com/p/1a160067d8fd 【8】用树莓派播放视频： 树莓派上可以播放 H264 和 mp4 等视频格式，1080p也没问题，因为这种格式的文件有硬件加速。 首先安装 安装 omxplayer ，这是一个命令行的播放器： 1sudo apt-get install omxplayer 然后就可以播放了，当然需要通过 HDMI 连接到显示器看： 1omxplayer -o hdmi /path/to/filename.mp4 -o hdmi 表示音频直接通过 HDMI 播放，播放时按左右箭头快进、按 q 退出。 更多命令行选项和播放时的控制快捷键请参考 omxplayer 的文档。 【9】树莓派安装 JDK： 首先是安装JDK 1sudo apt-get install oracle-java8-jdk 也可以在这个地方下载 修改环境变量，我用的版本是JDK8，arm版HFLT，代表arm架构硬件浮点运算，放在/usr/lib/jvm/jdk-8-oracle-arm-vfp-hflt这个文件夹了 1sudo nano /etc/profile 1234567[cc lang=\"php\"]#set java environmentJAVA_HOME=/usr/lib/jvm/jdk-8-oracle-arm-vfp-hfltCLASSPATH=.:$JAVA_HOME/jre/lib/rt.jar:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/toolPATH=$JAVA_HOME/bin:$PATHexport JAVA_HOME CLASSPATH PATH[/cc] 接下来是重启树莓派，看看版本号： 1java -version 【10】树莓派去黑边： 在使用树莓派连接HDMI电脑显示器的时候，可能会出现屏幕显示不全，有黑边的情况。这时候需要调节分辨率以适应屏幕。 进入树莓派系统，输入以下指令设置config.txt文件： 1sudo vi /boot/config.txt 调节任何参数时，将#号去除即可生效 123# uncomment to force a specific HDMI mode (this will force VGA) hdmi_group=2 //将显示模式切换成DMT（显示器模式） hdmi_mode=82 //1920x1080 60Hz 1080p 如果显示器不是1080P。则可以参考注1参数修改 这时候就将显示设置成1080P的分辨率，但是是不带声音的，如果你的显示器支持HDMI声音输出或者自带音响，则将如下代码参数去除#号解锁强制获取声音。 12# uncomment to force a HDMI mode rather than DVI. This can make audio work in # DMT (computer monitor) modes hdmi_drive=2 //HDMI模式 更多设置参考官方配置文档：https://www.raspberrypi.org/documentation/configuration/config-txt.md 注1： DMT模式分辨率参数 hdmi_mode resolution frequency notes 1 640x350 85Hz 2 640x400 85Hz 3 720x400 85Hz 4 640x480 60Hz 5 640x480 72Hz 6 640x480 75Hz 7 640x480 85Hz 8 800x600 56Hz 9 800x600 60Hz 10 800x600 72Hz 11 800x600 75Hz 12 800x600 85Hz 13 800x600 120Hz 14 848x480 60Hz 15 1024x768 43Hz incompatible with the Raspberry Pi 16 1024x768 60Hz 17 1024x768 70Hz 18 1024x768 75Hz 19 1024x768 85Hz 20 1024x768 120Hz 21 1152x864 75Hz 22 1280x768 reduced blanking 23 1280x768 60Hz 24 1280x768 75Hz 25 1280x768 85Hz 26 1280x768 120Hz reduced blanking 27 1280x800 reduced blanking 28 1280x800 60Hz 29 1280x800 75Hz 30 1280x800 85Hz 31 1280x800 120Hz reduced blanking 32 1280x960 60Hz 33 1280x960 85Hz 34 1280x960 120Hz reduced blanking 35 1280x1024 60Hz 36 1280x1024 75Hz 37 1280x1024 85Hz 38 1280x1024 120Hz reduced blanking 39 1360x768 60Hz 40 1360x768 120Hz reduced blanking 41 1400x1050 reduced blanking 42 1400x1050 60Hz 43 1400x1050 75Hz 44 1400x1050 85Hz 45 1400x1050 120Hz reduced blanking 46 1440x900 reduced blanking 47 1440x900 60Hz 48 1440x900 75Hz 49 1440x900 85Hz 50 1440x900 120Hz reduced blanking 51 1600x1200 60Hz 52 1600x1200 65Hz 53 1600x1200 70Hz 54 1600x1200 75Hz 55 1600x1200 85Hz 56 1600x1200 120Hz reduced blanking 57 1680x1050 reduced blanking 58 1680x1050 60Hz 59 1680x1050 75Hz 60 1680x1050 85Hz 61 1680x1050 120Hz reduced blanking 62 1792x1344 60Hz 63 1792x1344 75Hz 64 1792x1344 120Hz reduced blanking 65 1856x1392 60Hz 66 1856x1392 75Hz 67 1856x1392 120Hz reduced blanking 68 1920x1200 reduced blanking 69 1920x1200 60Hz 70 1920x1200 75Hz 71 1920x1200 85Hz 72 1920x1200 120Hz reduced blanking 73 1920x1440 60Hz 74 1920x1440 75Hz 75 1920x1440 120Hz reduced blanking 76 2560x1600 reduced blanking 77 2560x1600 60Hz 78 2560x1600 75Hz 79 2560x1600 85Hz 80 2560x1600 120Hz reduced blanking 81 1366x768 60Hz 82 1920x1080 60Hz 1080p 83 1600x900 reduced blanking 84 2048x1152 reduced blanking 85 1280x720 60Hz 720p 86 1366x768 reduced blanking 【11】OmxPlayer 调节声音大小： to provide more precise information for playing through scripts, there are 3 ways to change sound volume in current version of omxplayer, and values are not so intuitive: on starting command line, param –vol YYY, double millibels, default 0, range [-6000:0] by stdin interface, sending +/- to omxplayer will increase/decrease volume for 300 dmbels with DBUS interface, cmd ‘set volume’, value double:XXX, default 1, range [0:1] xxx to yyy relation is: XXX = 10 ^ (YYY / 2000) … according to omxplayer.cpp source code, reverse formula would be: YYY = 2000 * (log XXX). so if we need: volume 1%, XXX=0.01 and YYY=-4000 (10^(-4000/2000)=10^-2=0.01 volume 10%, XXX=0.1 and YYY=-2000 (10^(-2000/2000)=10^-1=0.1 volume 50%, XXX=0.5 and YYY=-602 (10^(-602/2000))~=0.5 volume 100%, XXX=1 and YYY=0 (10^(0/2000)=10^0=1) volume 150%, XXX=1.5 and YYY=352 … (for boost test, normal values are &lt;=100%) working bash script for dbus volume command: 123456export DBUS_SESSION_BUS_ADDRESS=$(cat /tmp/omxplayerdbus.$&#123;USER:-root&#125;) \\dbus-send --print-reply --session --reply-timeout=500 \\ --dest=org.mpris.MediaPlayer2.omxplayer \\ /org/mpris/MediaPlayer2 org.freedesktop.DBus.Properties.Set\\ string:\"org.mpris.MediaPlayer2.Player\" \\ string:\"Volume\" double:0.5 # &lt;-- XXX=0.5 (50% sound volume) equals to volume parameter at startup: 1omxplayer --vol -602 mediaFileName.mp4 … both sets sound volume to 50%. 【12】树莓派设置不休眠的方法 树莓派长时间没人操作时，会自动进入休眠状态，这是因为长时间无操作触发linux的节电休眠机制。所以当树莓派运行后台程序，比如用树莓派看视频时，时间一长就会自动黑屏，树莓派自动进入休眠状态。 怎么设置树莓派不休眠，其实通过建立和设置内置文件就行了，很简单。 以下是防止树莓派休眠的设置步骤： 1、用管理员root账户登录树莓派，在文件夹/etc/profile.d/里面新建内置文件screen.sh。 2、编辑文件screen.sh，写入以下两行内容: 12xset dpms 0 0 0xset s off 保存文件。 3、重启树莓派，就能实现永久禁用树莓派休眠。 【13】树莓派中的GPU渲染内存设置 为了平衡树莓派CPU运行内存和GPU渲染内存，将GPU的MemorySplit设置成320M这个经验值（总内存1GB，GPU分得320M，则CPU持有704M）是一个不错的选择，设置方法如下： raspi-config&gt;&gt;Advanced Options&gt;&gt;Memory Split&gt;&gt;更改内存为320","categories":[],"tags":[{"name":"raspberry","slug":"raspberry","permalink":"http://yoursite.com/tags/raspberry/"},{"name":"linux","slug":"linux","permalink":"http://yoursite.com/tags/linux/"}]},{"title":"Hello World","slug":"hello-world","date":"2019-11-18T02:02:50.485Z","updated":"2019-11-18T07:27:27.737Z","comments":true,"path":"2019/11/18/hello-world/","link":"","permalink":"http://yoursite.com/2019/11/18/hello-world/","excerpt":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}]}